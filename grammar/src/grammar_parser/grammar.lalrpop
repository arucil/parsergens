use lalrpop_util::ParseError;
use super::ast::*;
use super::lex;
use super::UserParseError;
use super::regex;

#[LALR]
grammar<'input>(input: &'input str);

pub Document: Grammar = <decl*>
  => {
    <>.into_iter()
      .filter_map(|x| x)
      .collect()
  };

decl: Option<Spanned<Decl>> = {
  <l:@L> <decl:rule_decl> <r:@L> => Some(Spanned(l..r, Decl::Rule(decl))),
  <l:@L> <decl:start_decl> <r:@L> => Some(Spanned(l..r, Decl::Start(decl))),
  <l:@L> <decl:token_decl> <r:@L> => Some(Spanned(l..r, Decl::Token(decl))),
  <l:@L> <decl:skip_decl> <r:@L> => Some(Spanned(l..r, Decl::Skip(decl))),
  Newline => None,
};

rule_decl: RuleDecl =
  <name:ident> Assign (Newline Indent)? <alt1:production> Newline <mut alts:(Indent Or <production> Newline)*>
  => {
    alts.insert(0, alt1);
    RuleDecl {
      name,
      alts,
    }
  }; 

production: Spanned<RuleAlt> = {
  <l:@L> <terms:ident+> <r:@L> => Spanned(l..r, RuleAlt::Terms(terms)),
  <l:@L> epsilon <r:@L> => Spanned(l..r, RuleAlt::Epsilon),
};

epsilon: () = LParen RParen;

start_decl: StartDecl = Percent Start <name:ident> Newline
  => {
    StartDecl {
      name,
    }
  };

token_decl: TokenDecl = Percent Token <name:ident> <pattern:token_pattern>
  => {
    TokenDecl {
      name,
      pattern,
    }
  };

skip_decl: SkipDecl = Percent Skip <pattern:token_pattern>
  => {
    SkipDecl {
      pattern,
    }
  };

token_pattern: TokenPattern = {
  <regex:regex> =>? regex::parse_regex(
    &regex.1[1..regex.1.len() - 1],
    regex.0 .start + 1
  )
    .map(|x| TokenPattern::Regex(Spanned(regex.0, (regex.1, x))))
    .map_err(|error| ParseError::User {
      error: UserParseError::RegexError(error),
    }),
  <str:string> =>? regex::parse_raw_string(
    &str.1[1..str.1.len() - 1], str.0 .start
  )
    .map(|x| TokenPattern::String(Spanned(str.0, (str.1, x))))
    .map_err(|error| ParseError::user {
      error: UserParseError::RegexError(error)
    }),
}

spanned<T>: Spanned<String> = <l:@L> <x:T> <r:@L> => Spanned(l..r, x.text.to_owned());

ident = spanned<Ident>;
string = spanned<String>;
regex = spanned<Regex>;

extern {
  type Location = usize;
  type Error = UserParseError;

  enum lex::Token<'input> {
    Start => lex::Token { kind: lex::TokenKind::Start, .. },
    Token => lex::Token { kind: lex::TokenKind::Token, .. },
    Skip => lex::Token { kind: lex::TokenKind::Skip, .. },

    Ident => lex::Token { kind: lex::TokenKind::Ident, .. },
    Regex => lex::Token { kind: lex::TokenKind::Regex, .. },
    String => lex::Token { kind: lex::TokenKind::String, .. },

    Percent => lex::Token { kind: lex::TokenKind::Percent, .. },
    Assign => lex::Token { kind: lex::TokenKind::Assign, .. },
    Or => lex::Token { kind: lex::TokenKind::Or, .. },
    LParen => lex::Token { kind: lex::TokenKind::LParen, .. },
    RParen => lex::Token { kind: lex::TokenKind::RParen, .. },
    Comma => lex::Token { kind: lex::TokenKind::Comma, .. },

    Indent => lex::Token { kind: lex::TokenKind::Indent, .. },
    Newline => lex::Token { kind: lex::TokenKind::Newline, .. },
  }
}